{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlaSharma9/Connected-Minds/blob/main/Anomaly_Detection_in_Cellular_network_ila.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kLLFnQqhVZ3n"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import *\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv(\"/content/ML-MATT-CompetitionQT1920_train.csv\",encoding='windows-1252')\n",
        "data_test = pd.read_csv(\"/ML-MATT-CompetitionQT1920_test.csv\", encoding='windows-1252')\n",
        "\n",
        "print(data_train.shape)\n",
        "print(data_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8FISRwCVj8X",
        "outputId": "f030ceaa-add0-4b0e-a24d-38fc2c7c3fdc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36904, 14)\n",
            "(9158, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "QW5IBXrMmzVL",
        "outputId": "a8943a3a-dbbf-4b0e-b23b-f3b7545e70d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Time CellName  PRBUsageUL  PRBUsageDL  meanThr_DL  meanThr_UL  maxThr_DL  \\\n",
              "0  10:45    3BLTE      11.642       1.393       0.370       0.041     15.655   \n",
              "1   9:45    1BLTE      21.791       1.891       0.537       0.268     10.273   \n",
              "2   7:45    9BLTE       0.498       0.398       0.015       0.010      0.262   \n",
              "3   2:45    4ALTE       1.891       1.095       0.940       0.024     60.715   \n",
              "4   3:30   10BLTE       0.303       0.404       0.016       0.013      0.348   \n",
              "5  13:30    9ALTE      15.966       1.819       0.415       0.071     10.116   \n",
              "6  20:00    9BLTE       7.074       0.505       0.032       0.012      1.680   \n",
              "7   8:00    4BLTE       7.960       1.393       0.299       0.025     24.697   \n",
              "8  16:45    4CLTE      26.879       3.032       0.525       0.120      9.145   \n",
              "9   4:15    6CLTE       4.143       0.505       0.021       0.013      0.409   \n",
              "\n",
              "   maxThr_UL  meanUE_DL  meanUE_UL  maxUE_DL  maxUE_UL maxUE_UL+DL  Unusual  \n",
              "0      0.644      1.114      1.025       4.0       3.0           7        1  \n",
              "1      1.154      1.353      1.085       6.0       4.0          10        1  \n",
              "2      0.164      0.995      0.995       1.0       1.0           2        1  \n",
              "3      0.825      1.035      0.995       2.0       2.0           4        1  \n",
              "4      0.168      1.011      1.011       2.0       1.0           3        0  \n",
              "5      0.706      1.364      1.314       6.0       5.0          11        0  \n",
              "6      0.131      1.041      1.041       3.0       3.0           6        0  \n",
              "7      0.451      1.075      1.015       3.0       3.0           6        1  \n",
              "8      0.894      1.425      1.273       6.0       5.0          11        0  \n",
              "9      0.437      1.021      0.010       2.0       2.0           4        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37b0edc2-e1d9-4262-8fba-6f871a667e50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>CellName</th>\n",
              "      <th>PRBUsageUL</th>\n",
              "      <th>PRBUsageDL</th>\n",
              "      <th>meanThr_DL</th>\n",
              "      <th>meanThr_UL</th>\n",
              "      <th>maxThr_DL</th>\n",
              "      <th>maxThr_UL</th>\n",
              "      <th>meanUE_DL</th>\n",
              "      <th>meanUE_UL</th>\n",
              "      <th>maxUE_DL</th>\n",
              "      <th>maxUE_UL</th>\n",
              "      <th>maxUE_UL+DL</th>\n",
              "      <th>Unusual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10:45</td>\n",
              "      <td>3BLTE</td>\n",
              "      <td>11.642</td>\n",
              "      <td>1.393</td>\n",
              "      <td>0.370</td>\n",
              "      <td>0.041</td>\n",
              "      <td>15.655</td>\n",
              "      <td>0.644</td>\n",
              "      <td>1.114</td>\n",
              "      <td>1.025</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9:45</td>\n",
              "      <td>1BLTE</td>\n",
              "      <td>21.791</td>\n",
              "      <td>1.891</td>\n",
              "      <td>0.537</td>\n",
              "      <td>0.268</td>\n",
              "      <td>10.273</td>\n",
              "      <td>1.154</td>\n",
              "      <td>1.353</td>\n",
              "      <td>1.085</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7:45</td>\n",
              "      <td>9BLTE</td>\n",
              "      <td>0.498</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.262</td>\n",
              "      <td>0.164</td>\n",
              "      <td>0.995</td>\n",
              "      <td>0.995</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2:45</td>\n",
              "      <td>4ALTE</td>\n",
              "      <td>1.891</td>\n",
              "      <td>1.095</td>\n",
              "      <td>0.940</td>\n",
              "      <td>0.024</td>\n",
              "      <td>60.715</td>\n",
              "      <td>0.825</td>\n",
              "      <td>1.035</td>\n",
              "      <td>0.995</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3:30</td>\n",
              "      <td>10BLTE</td>\n",
              "      <td>0.303</td>\n",
              "      <td>0.404</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.348</td>\n",
              "      <td>0.168</td>\n",
              "      <td>1.011</td>\n",
              "      <td>1.011</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13:30</td>\n",
              "      <td>9ALTE</td>\n",
              "      <td>15.966</td>\n",
              "      <td>1.819</td>\n",
              "      <td>0.415</td>\n",
              "      <td>0.071</td>\n",
              "      <td>10.116</td>\n",
              "      <td>0.706</td>\n",
              "      <td>1.364</td>\n",
              "      <td>1.314</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>20:00</td>\n",
              "      <td>9BLTE</td>\n",
              "      <td>7.074</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.012</td>\n",
              "      <td>1.680</td>\n",
              "      <td>0.131</td>\n",
              "      <td>1.041</td>\n",
              "      <td>1.041</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8:00</td>\n",
              "      <td>4BLTE</td>\n",
              "      <td>7.960</td>\n",
              "      <td>1.393</td>\n",
              "      <td>0.299</td>\n",
              "      <td>0.025</td>\n",
              "      <td>24.697</td>\n",
              "      <td>0.451</td>\n",
              "      <td>1.075</td>\n",
              "      <td>1.015</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>16:45</td>\n",
              "      <td>4CLTE</td>\n",
              "      <td>26.879</td>\n",
              "      <td>3.032</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.120</td>\n",
              "      <td>9.145</td>\n",
              "      <td>0.894</td>\n",
              "      <td>1.425</td>\n",
              "      <td>1.273</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4:15</td>\n",
              "      <td>6CLTE</td>\n",
              "      <td>4.143</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.409</td>\n",
              "      <td>0.437</td>\n",
              "      <td>1.021</td>\n",
              "      <td>0.010</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37b0edc2-e1d9-4262-8fba-6f871a667e50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37b0edc2-e1d9-4262-8fba-6f871a667e50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37b0edc2-e1d9-4262-8fba-6f871a667e50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "sBvQMf-Dm1tx",
        "outputId": "05245de2-d875-4fae-cdc5-bf4fa521375c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Time CellName  PRBUsageUL  PRBUsageDL  meanThr_DL  meanThr_UL  maxThr_DL  \\\n",
              "0   3:00    6ALTE       3.781       1.493       0.575       0.042     22.659   \n",
              "1  20:30    6ULTE       2.021       3.335       0.569       0.075     29.265   \n",
              "2  11:30    2ALTE       0.505       0.404       0.014       0.010      0.227   \n",
              "3   6:45    3CLTE       1.011       0.505       0.238       0.021     20.962   \n",
              "4  15:45    6CLTE       3.881       0.498       0.076       0.041      3.936   \n",
              "5  23:45    7CLTE       0.199       0.697       0.487       0.018     29.461   \n",
              "6   9:15    1BLTE       9.297       1.718       0.754       0.074     15.944   \n",
              "7  21:30    3CLTE       6.568       2.324       0.699       0.058     32.333   \n",
              "8   2:00    2ALTE       0.000       0.404       0.003       0.003      0.003   \n",
              "9  11:45    3ALTE      14.627       1.891       0.440       0.065     14.611   \n",
              "\n",
              "   maxThr_UL  meanUE_DL  meanUE_UL  maxUE_DL  maxUE_UL  maxUE_UL+DL  \n",
              "0      0.743      0.985      0.010       3.0       2.0          5.0  \n",
              "1      1.049      1.314      0.010       6.0       3.0          9.0  \n",
              "2      0.097      1.011      0.010       2.0       1.0          3.0  \n",
              "3      0.609      1.011      1.011       2.0       1.0          3.0  \n",
              "4      1.768      1.025      0.010       3.0       2.0          5.0  \n",
              "5      0.670      1.045      0.010       3.0       2.0          5.0  \n",
              "6      2.416      1.192      1.041       4.0       3.0          7.0  \n",
              "7      1.186      1.112      1.021       4.0       3.0          7.0  \n",
              "8      0.003      1.011      0.010       1.0       1.0          2.0  \n",
              "9      0.696      1.254      1.124       5.0       4.0          9.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4220d55b-9e28-4b7f-b17f-1502ac2c2829\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>CellName</th>\n",
              "      <th>PRBUsageUL</th>\n",
              "      <th>PRBUsageDL</th>\n",
              "      <th>meanThr_DL</th>\n",
              "      <th>meanThr_UL</th>\n",
              "      <th>maxThr_DL</th>\n",
              "      <th>maxThr_UL</th>\n",
              "      <th>meanUE_DL</th>\n",
              "      <th>meanUE_UL</th>\n",
              "      <th>maxUE_DL</th>\n",
              "      <th>maxUE_UL</th>\n",
              "      <th>maxUE_UL+DL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3:00</td>\n",
              "      <td>6ALTE</td>\n",
              "      <td>3.781</td>\n",
              "      <td>1.493</td>\n",
              "      <td>0.575</td>\n",
              "      <td>0.042</td>\n",
              "      <td>22.659</td>\n",
              "      <td>0.743</td>\n",
              "      <td>0.985</td>\n",
              "      <td>0.010</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20:30</td>\n",
              "      <td>6ULTE</td>\n",
              "      <td>2.021</td>\n",
              "      <td>3.335</td>\n",
              "      <td>0.569</td>\n",
              "      <td>0.075</td>\n",
              "      <td>29.265</td>\n",
              "      <td>1.049</td>\n",
              "      <td>1.314</td>\n",
              "      <td>0.010</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11:30</td>\n",
              "      <td>2ALTE</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.404</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.227</td>\n",
              "      <td>0.097</td>\n",
              "      <td>1.011</td>\n",
              "      <td>0.010</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6:45</td>\n",
              "      <td>3CLTE</td>\n",
              "      <td>1.011</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.238</td>\n",
              "      <td>0.021</td>\n",
              "      <td>20.962</td>\n",
              "      <td>0.609</td>\n",
              "      <td>1.011</td>\n",
              "      <td>1.011</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15:45</td>\n",
              "      <td>6CLTE</td>\n",
              "      <td>3.881</td>\n",
              "      <td>0.498</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.041</td>\n",
              "      <td>3.936</td>\n",
              "      <td>1.768</td>\n",
              "      <td>1.025</td>\n",
              "      <td>0.010</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>23:45</td>\n",
              "      <td>7CLTE</td>\n",
              "      <td>0.199</td>\n",
              "      <td>0.697</td>\n",
              "      <td>0.487</td>\n",
              "      <td>0.018</td>\n",
              "      <td>29.461</td>\n",
              "      <td>0.670</td>\n",
              "      <td>1.045</td>\n",
              "      <td>0.010</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9:15</td>\n",
              "      <td>1BLTE</td>\n",
              "      <td>9.297</td>\n",
              "      <td>1.718</td>\n",
              "      <td>0.754</td>\n",
              "      <td>0.074</td>\n",
              "      <td>15.944</td>\n",
              "      <td>2.416</td>\n",
              "      <td>1.192</td>\n",
              "      <td>1.041</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>21:30</td>\n",
              "      <td>3CLTE</td>\n",
              "      <td>6.568</td>\n",
              "      <td>2.324</td>\n",
              "      <td>0.699</td>\n",
              "      <td>0.058</td>\n",
              "      <td>32.333</td>\n",
              "      <td>1.186</td>\n",
              "      <td>1.112</td>\n",
              "      <td>1.021</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2:00</td>\n",
              "      <td>2ALTE</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.404</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "      <td>1.011</td>\n",
              "      <td>0.010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11:45</td>\n",
              "      <td>3ALTE</td>\n",
              "      <td>14.627</td>\n",
              "      <td>1.891</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.065</td>\n",
              "      <td>14.611</td>\n",
              "      <td>0.696</td>\n",
              "      <td>1.254</td>\n",
              "      <td>1.124</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4220d55b-9e28-4b7f-b17f-1502ac2c2829')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4220d55b-9e28-4b7f-b17f-1502ac2c2829 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4220d55b-9e28-4b7f-b17f-1502ac2c2829');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "BTPkefL0mqEI",
        "outputId": "13b57ea5-5556-4bba-8fd2-de80b7688110"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         PRBUsageUL    PRBUsageDL    meanThr_DL    meanThr_UL     maxThr_DL  \\\n",
              "count  36904.000000  36904.000000  36904.000000  36904.000000  36904.000000   \n",
              "mean       7.835090      2.106396      0.560525      0.067610     17.764369   \n",
              "std        8.428206      2.247514      0.727623      0.186555     15.739932   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        1.213000      0.707000      0.140000      0.021000      5.710750   \n",
              "50%        4.547000      1.314000      0.352000      0.040000     14.170000   \n",
              "75%       12.126000      2.728000      0.718000      0.075000     25.059500   \n",
              "max       51.333000     77.505000     19.601000     12.461000    140.008000   \n",
              "\n",
              "          maxThr_UL     meanUE_DL     meanUE_UL      maxUE_DL      maxUE_UL  \\\n",
              "count  36904.000000  36904.000000  36904.000000  36815.000000  36815.000000   \n",
              "mean       1.791974      1.173441      0.665143      4.190819      3.063371   \n",
              "std        5.028928      0.214065      0.535493      1.772484      1.387446   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.362000      1.041000      0.010000      3.000000      2.000000   \n",
              "50%        0.703000      1.112000      1.011000      4.000000      3.000000   \n",
              "75%        1.242000      1.263000      1.051000      5.000000      4.000000   \n",
              "max       48.253000      2.915000      2.668000     12.000000     12.000000   \n",
              "\n",
              "            Unusual  \n",
              "count  36904.000000  \n",
              "mean       0.275932  \n",
              "std        0.446989  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        1.000000  \n",
              "max        1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-473f1731-1e49-44ac-b437-3727e5512469\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRBUsageUL</th>\n",
              "      <th>PRBUsageDL</th>\n",
              "      <th>meanThr_DL</th>\n",
              "      <th>meanThr_UL</th>\n",
              "      <th>maxThr_DL</th>\n",
              "      <th>maxThr_UL</th>\n",
              "      <th>meanUE_DL</th>\n",
              "      <th>meanUE_UL</th>\n",
              "      <th>maxUE_DL</th>\n",
              "      <th>maxUE_UL</th>\n",
              "      <th>Unusual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>36904.000000</td>\n",
              "      <td>36904.000000</td>\n",
              "      <td>36904.000000</td>\n",
              "      <td>36904.000000</td>\n",
              "      <td>36904.000000</td>\n",
              "      <td>36904.000000</td>\n",
              "      <td>36904.000000</td>\n",
              "      <td>36904.000000</td>\n",
              "      <td>36815.000000</td>\n",
              "      <td>36815.000000</td>\n",
              "      <td>36904.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.835090</td>\n",
              "      <td>2.106396</td>\n",
              "      <td>0.560525</td>\n",
              "      <td>0.067610</td>\n",
              "      <td>17.764369</td>\n",
              "      <td>1.791974</td>\n",
              "      <td>1.173441</td>\n",
              "      <td>0.665143</td>\n",
              "      <td>4.190819</td>\n",
              "      <td>3.063371</td>\n",
              "      <td>0.275932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.428206</td>\n",
              "      <td>2.247514</td>\n",
              "      <td>0.727623</td>\n",
              "      <td>0.186555</td>\n",
              "      <td>15.739932</td>\n",
              "      <td>5.028928</td>\n",
              "      <td>0.214065</td>\n",
              "      <td>0.535493</td>\n",
              "      <td>1.772484</td>\n",
              "      <td>1.387446</td>\n",
              "      <td>0.446989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.213000</td>\n",
              "      <td>0.707000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.021000</td>\n",
              "      <td>5.710750</td>\n",
              "      <td>0.362000</td>\n",
              "      <td>1.041000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.547000</td>\n",
              "      <td>1.314000</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>14.170000</td>\n",
              "      <td>0.703000</td>\n",
              "      <td>1.112000</td>\n",
              "      <td>1.011000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12.126000</td>\n",
              "      <td>2.728000</td>\n",
              "      <td>0.718000</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>25.059500</td>\n",
              "      <td>1.242000</td>\n",
              "      <td>1.263000</td>\n",
              "      <td>1.051000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>51.333000</td>\n",
              "      <td>77.505000</td>\n",
              "      <td>19.601000</td>\n",
              "      <td>12.461000</td>\n",
              "      <td>140.008000</td>\n",
              "      <td>48.253000</td>\n",
              "      <td>2.915000</td>\n",
              "      <td>2.668000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-473f1731-1e49-44ac-b437-3727e5512469')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-473f1731-1e49-44ac-b437-3727e5512469 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-473f1731-1e49-44ac-b437-3727e5512469');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "0pV1uhC4msdg",
        "outputId": "87dc8086-2f83-48ca-b607-d612a8e3ea14"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        PRBUsageUL   PRBUsageDL   meanThr_DL   meanThr_UL    maxThr_DL  \\\n",
              "count  9158.000000  9158.000000  9158.000000  9158.000000  9158.000000   \n",
              "mean      7.731205     2.060441     0.553921     0.063983    17.586196   \n",
              "std       8.375197     2.250347     0.731108     0.107254    15.911279   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       1.112000     0.707000     0.133000     0.021000     5.360750   \n",
              "50%       4.345000     1.314000     0.341000     0.039000    13.759000   \n",
              "75%      12.025000     2.728000     0.715000     0.073000    24.980500   \n",
              "max      46.887000    77.303000    15.030000     2.991000   118.269000   \n",
              "\n",
              "         maxThr_UL    meanUE_DL    meanUE_UL     maxUE_DL     maxUE_UL  \\\n",
              "count  9158.000000  9158.000000  9158.000000  9156.000000  9156.000000   \n",
              "mean      1.804874     1.173203     0.660564     4.166448     3.037789   \n",
              "std       5.119961     0.202514     0.534836     1.766189     1.376915   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.354000     1.041000     0.010000     3.000000     2.000000   \n",
              "50%       0.699000     1.112000     1.011000     4.000000     3.000000   \n",
              "75%       1.257000     1.254000     1.051000     5.000000     4.000000   \n",
              "max      47.118000     2.930000     2.162000    11.000000    10.000000   \n",
              "\n",
              "       maxUE_UL+DL  \n",
              "count  9156.000000  \n",
              "mean      7.204238  \n",
              "std       3.034304  \n",
              "min       0.000000  \n",
              "25%       5.000000  \n",
              "50%       7.000000  \n",
              "75%       9.000000  \n",
              "max      21.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-caf6816d-bd82-493a-86c2-e7711ffb05cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRBUsageUL</th>\n",
              "      <th>PRBUsageDL</th>\n",
              "      <th>meanThr_DL</th>\n",
              "      <th>meanThr_UL</th>\n",
              "      <th>maxThr_DL</th>\n",
              "      <th>maxThr_UL</th>\n",
              "      <th>meanUE_DL</th>\n",
              "      <th>meanUE_UL</th>\n",
              "      <th>maxUE_DL</th>\n",
              "      <th>maxUE_UL</th>\n",
              "      <th>maxUE_UL+DL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9158.000000</td>\n",
              "      <td>9158.000000</td>\n",
              "      <td>9158.000000</td>\n",
              "      <td>9158.000000</td>\n",
              "      <td>9158.000000</td>\n",
              "      <td>9158.000000</td>\n",
              "      <td>9158.000000</td>\n",
              "      <td>9158.000000</td>\n",
              "      <td>9156.000000</td>\n",
              "      <td>9156.000000</td>\n",
              "      <td>9156.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.731205</td>\n",
              "      <td>2.060441</td>\n",
              "      <td>0.553921</td>\n",
              "      <td>0.063983</td>\n",
              "      <td>17.586196</td>\n",
              "      <td>1.804874</td>\n",
              "      <td>1.173203</td>\n",
              "      <td>0.660564</td>\n",
              "      <td>4.166448</td>\n",
              "      <td>3.037789</td>\n",
              "      <td>7.204238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.375197</td>\n",
              "      <td>2.250347</td>\n",
              "      <td>0.731108</td>\n",
              "      <td>0.107254</td>\n",
              "      <td>15.911279</td>\n",
              "      <td>5.119961</td>\n",
              "      <td>0.202514</td>\n",
              "      <td>0.534836</td>\n",
              "      <td>1.766189</td>\n",
              "      <td>1.376915</td>\n",
              "      <td>3.034304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.112000</td>\n",
              "      <td>0.707000</td>\n",
              "      <td>0.133000</td>\n",
              "      <td>0.021000</td>\n",
              "      <td>5.360750</td>\n",
              "      <td>0.354000</td>\n",
              "      <td>1.041000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.345000</td>\n",
              "      <td>1.314000</td>\n",
              "      <td>0.341000</td>\n",
              "      <td>0.039000</td>\n",
              "      <td>13.759000</td>\n",
              "      <td>0.699000</td>\n",
              "      <td>1.112000</td>\n",
              "      <td>1.011000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>12.025000</td>\n",
              "      <td>2.728000</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>0.073000</td>\n",
              "      <td>24.980500</td>\n",
              "      <td>1.257000</td>\n",
              "      <td>1.254000</td>\n",
              "      <td>1.051000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>46.887000</td>\n",
              "      <td>77.303000</td>\n",
              "      <td>15.030000</td>\n",
              "      <td>2.991000</td>\n",
              "      <td>118.269000</td>\n",
              "      <td>47.118000</td>\n",
              "      <td>2.930000</td>\n",
              "      <td>2.162000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-caf6816d-bd82-493a-86c2-e7711ffb05cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-caf6816d-bd82-493a-86c2-e7711ffb05cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-caf6816d-bd82-493a-86c2-e7711ffb05cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wh4JNxeBmulN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data_train.drop(columns=['CellName','Time'], axis=1)\n",
        "data_test = data_test.drop(columns=['CellName','Time'], axis=1)"
      ],
      "metadata": {
        "id": "F2ArBbuJkeAa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have an unusual value in **maxUE_UL+DL** column of our dataframe , so we need to handle this by removing and replacing values"
      ],
      "metadata": {
        "id": "6yFipNa61U2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train[data_train.eq('#VALOR!').any(1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Vo2pFJl41TF3",
        "outputId": "d8ffb7c1-379d-4906-b452-1de3f3dc6d23"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       PRBUsageUL  PRBUsageDL  meanThr_DL  meanThr_UL  maxThr_DL  maxThr_UL  \\\n",
              "51         13.743       4.042       2.113       0.100     44.483      1.110   \n",
              "1290       22.837       2.324       0.500       0.090     24.374      0.847   \n",
              "2082        0.199       1.791       0.693       0.032     15.634      0.353   \n",
              "2842        9.903       1.516       0.466       0.032     24.576      0.931   \n",
              "3384        0.404       0.909       0.216       0.042      9.730      2.714   \n",
              "...           ...         ...         ...         ...        ...        ...   \n",
              "36036       1.516       0.505       0.078       0.013      1.298      0.267   \n",
              "36046      15.360       2.829       1.149       0.071     39.615      0.947   \n",
              "36317      30.921       4.042       1.450       0.175     26.369      1.487   \n",
              "36652       0.606       1.819       0.255       0.027     14.546      0.820   \n",
              "36687       1.011       2.021       0.310       0.042     17.361      2.394   \n",
              "\n",
              "       meanUE_DL  meanUE_UL  maxUE_DL  maxUE_UL maxUE_UL+DL  Unusual  \n",
              "51           0.0        0.0       NaN       NaN    #VALOR!        0  \n",
              "1290         0.0        0.0       NaN       NaN    #VALOR!        0  \n",
              "2082         0.0        0.0       NaN       NaN    #VALOR!        1  \n",
              "2842         0.0        0.0       NaN       NaN    #VALOR!        0  \n",
              "3384         0.0        0.0       NaN       NaN    #VALOR!        0  \n",
              "...          ...        ...       ...       ...         ...      ...  \n",
              "36036        0.0        0.0       NaN       NaN    #VALOR!        0  \n",
              "36046        0.0        0.0       NaN       NaN    #VALOR!        0  \n",
              "36317        0.0        0.0       NaN       NaN    #VALOR!        0  \n",
              "36652        0.0        0.0       NaN       NaN    #VALOR!        0  \n",
              "36687        0.0        0.0       NaN       NaN    #VALOR!        0  \n",
              "\n",
              "[84 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9d2a96c-dd0c-4aa9-932c-6a98ffe89c51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRBUsageUL</th>\n",
              "      <th>PRBUsageDL</th>\n",
              "      <th>meanThr_DL</th>\n",
              "      <th>meanThr_UL</th>\n",
              "      <th>maxThr_DL</th>\n",
              "      <th>maxThr_UL</th>\n",
              "      <th>meanUE_DL</th>\n",
              "      <th>meanUE_UL</th>\n",
              "      <th>maxUE_DL</th>\n",
              "      <th>maxUE_UL</th>\n",
              "      <th>maxUE_UL+DL</th>\n",
              "      <th>Unusual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>13.743</td>\n",
              "      <td>4.042</td>\n",
              "      <td>2.113</td>\n",
              "      <td>0.100</td>\n",
              "      <td>44.483</td>\n",
              "      <td>1.110</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>22.837</td>\n",
              "      <td>2.324</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.090</td>\n",
              "      <td>24.374</td>\n",
              "      <td>0.847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2082</th>\n",
              "      <td>0.199</td>\n",
              "      <td>1.791</td>\n",
              "      <td>0.693</td>\n",
              "      <td>0.032</td>\n",
              "      <td>15.634</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2842</th>\n",
              "      <td>9.903</td>\n",
              "      <td>1.516</td>\n",
              "      <td>0.466</td>\n",
              "      <td>0.032</td>\n",
              "      <td>24.576</td>\n",
              "      <td>0.931</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3384</th>\n",
              "      <td>0.404</td>\n",
              "      <td>0.909</td>\n",
              "      <td>0.216</td>\n",
              "      <td>0.042</td>\n",
              "      <td>9.730</td>\n",
              "      <td>2.714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36036</th>\n",
              "      <td>1.516</td>\n",
              "      <td>0.505</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.013</td>\n",
              "      <td>1.298</td>\n",
              "      <td>0.267</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36046</th>\n",
              "      <td>15.360</td>\n",
              "      <td>2.829</td>\n",
              "      <td>1.149</td>\n",
              "      <td>0.071</td>\n",
              "      <td>39.615</td>\n",
              "      <td>0.947</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36317</th>\n",
              "      <td>30.921</td>\n",
              "      <td>4.042</td>\n",
              "      <td>1.450</td>\n",
              "      <td>0.175</td>\n",
              "      <td>26.369</td>\n",
              "      <td>1.487</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36652</th>\n",
              "      <td>0.606</td>\n",
              "      <td>1.819</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.027</td>\n",
              "      <td>14.546</td>\n",
              "      <td>0.820</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36687</th>\n",
              "      <td>1.011</td>\n",
              "      <td>2.021</td>\n",
              "      <td>0.310</td>\n",
              "      <td>0.042</td>\n",
              "      <td>17.361</td>\n",
              "      <td>2.394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#VALOR!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows  12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9d2a96c-dd0c-4aa9-932c-6a98ffe89c51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9d2a96c-dd0c-4aa9-932c-6a98ffe89c51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9d2a96c-dd0c-4aa9-932c-6a98ffe89c51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['maxUE_UL+DL'].value_counts()['#VALOR!']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L-508Ud1Tr0",
        "outputId": "abd2edd3-d6de-48fb-ad5e-186c8c5a30e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test[data_test.eq('#VALOR!').any(1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "Di_qBatJ17JD",
        "outputId": "42f1cc09-258c-4b97-f9ab-0a7ca3b81309"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [PRBUsageUL, PRBUsageDL, meanThr_DL, meanThr_UL, maxThr_DL, maxThr_UL, meanUE_DL, meanUE_UL, maxUE_DL, maxUE_UL, maxUE_UL+DL]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d121cc9-f883-4764-94b0-6eba75aea82b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRBUsageUL</th>\n",
              "      <th>PRBUsageDL</th>\n",
              "      <th>meanThr_DL</th>\n",
              "      <th>meanThr_UL</th>\n",
              "      <th>maxThr_DL</th>\n",
              "      <th>maxThr_UL</th>\n",
              "      <th>meanUE_DL</th>\n",
              "      <th>meanUE_UL</th>\n",
              "      <th>maxUE_DL</th>\n",
              "      <th>maxUE_UL</th>\n",
              "      <th>maxUE_UL+DL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d121cc9-f883-4764-94b0-6eba75aea82b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d121cc9-f883-4764-94b0-6eba75aea82b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d121cc9-f883-4764-94b0-6eba75aea82b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we understand that the value '#VALOR!' needs to be replaced by a numeric value**"
      ],
      "metadata": {
        "id": "SqWLJ3pt2Ecq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['maxUE_UL+DL'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxdhxDyA2O_S",
        "outputId": "68e689a7-9216-44ca-df71-65932f85cccc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['7', '10', '2', '4', '3', '11', '6', '8', '5', '9', '12',\n",
              "       '#VALOR!', '14', '17', '0', '13', '15', '16', '18', '19', '1',\n",
              "       '20', '23', nan, '21'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will replace the value '#VALOR!' by 0**"
      ],
      "metadata": {
        "id": "Qc3h7CfK3Tnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['maxUE_UL+DL'] = data_train['maxUE_UL+DL'].replace('#VALOR!',0)"
      ],
      "metadata": {
        "id": "kZCYVe1W3gDV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train['maxUE_UL+DL']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gJELbQL4NtG",
        "outputId": "fc76c5e3-87fb-4bb2-8025-e97b7ea1289a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         7\n",
              "1        10\n",
              "2         2\n",
              "3         4\n",
              "4         3\n",
              "         ..\n",
              "36899     7\n",
              "36900     6\n",
              "36901     7\n",
              "36902     9\n",
              "36903    10\n",
              "Name: maxUE_UL+DL, Length: 36904, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train[data_train.eq('#VALOR!').any(1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "gvOTyuPb4QL7",
        "outputId": "5c3fd9f9-baea-4e05-a8a8-affe1d453c89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [PRBUsageUL, PRBUsageDL, meanThr_DL, meanThr_UL, maxThr_DL, maxThr_UL, meanUE_DL, meanUE_UL, maxUE_DL, maxUE_UL, maxUE_UL+DL, Unusual]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82bf4799-5207-4e7f-85fd-473b7d7411d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRBUsageUL</th>\n",
              "      <th>PRBUsageDL</th>\n",
              "      <th>meanThr_DL</th>\n",
              "      <th>meanThr_UL</th>\n",
              "      <th>maxThr_DL</th>\n",
              "      <th>maxThr_UL</th>\n",
              "      <th>meanUE_DL</th>\n",
              "      <th>meanUE_UL</th>\n",
              "      <th>maxUE_DL</th>\n",
              "      <th>maxUE_UL</th>\n",
              "      <th>maxUE_UL+DL</th>\n",
              "      <th>Unusual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82bf4799-5207-4e7f-85fd-473b7d7411d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82bf4799-5207-4e7f-85fd-473b7d7411d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82bf4799-5207-4e7f-85fd-473b7d7411d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We have finally replaced the value and now we will proceed with Normalization**"
      ],
      "metadata": {
        "id": "ObO8LAsR4W9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalization of training dataset**"
      ],
      "metadata": {
        "id": "gVSCzTNc5qvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "np_scaled = min_max_scaler.fit_transform(data_train)\n",
        "\n",
        "df_train = pd.DataFrame(np_scaled, columns = data_train.columns)\n",
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "B1fwafK64dEz",
        "outputId": "6470a862-a619-4fba-e1f8-fc78bd0bf8ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       PRBUsageUL  PRBUsageDL  meanThr_DL  meanThr_UL  maxThr_DL  maxThr_UL  \\\n",
              "0        0.226794    0.017973    0.018877    0.003290   0.111815   0.013346   \n",
              "1        0.424503    0.024398    0.027397    0.021507   0.073374   0.023916   \n",
              "2        0.009701    0.005135    0.000765    0.000803   0.001871   0.003399   \n",
              "3        0.036838    0.014128    0.047957    0.001926   0.433654   0.017097   \n",
              "4        0.005903    0.005213    0.000816    0.001043   0.002486   0.003482   \n",
              "...           ...         ...         ...         ...        ...        ...   \n",
              "36899    0.147644    0.010425    0.008367    0.002969   0.056997   0.007772   \n",
              "36900    0.177176    0.015651    0.009642    0.002408   0.139349   0.032806   \n",
              "36901    0.085286    0.011561    0.017397    0.002408   0.085974   0.011191   \n",
              "36902    0.259852    0.035198    0.028519    0.005216   0.201324   0.018527   \n",
              "36903    0.433074    0.033895    0.041528    0.006099   0.577138   0.017657   \n",
              "\n",
              "       meanUE_DL  meanUE_UL  maxUE_DL  maxUE_UL  maxUE_UL+DL  Unusual  \n",
              "0       0.382161   0.384183  0.333333  0.250000     0.304348      1.0  \n",
              "1       0.464151   0.406672  0.500000  0.333333     0.434783      1.0  \n",
              "2       0.341338   0.372939  0.083333  0.083333     0.086957      1.0  \n",
              "3       0.355060   0.372939  0.166667  0.166667     0.173913      1.0  \n",
              "4       0.346827   0.378936  0.166667  0.083333     0.130435      0.0  \n",
              "...          ...        ...       ...       ...          ...      ...  \n",
              "36899   0.377702   0.003748  0.333333  0.250000     0.304348      0.0  \n",
              "36900   0.384906   0.386432  0.333333  0.166667     0.260870      0.0  \n",
              "36901   0.365352   0.376687  0.333333  0.250000     0.304348      1.0  \n",
              "36902   0.419554   0.397676  0.416667  0.333333     0.391304      0.0  \n",
              "36903   0.454202   0.428036  0.500000  0.333333     0.434783      0.0  \n",
              "\n",
              "[36904 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1addc1e4-d249-42df-a51d-02400e1b95ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRBUsageUL</th>\n",
              "      <th>PRBUsageDL</th>\n",
              "      <th>meanThr_DL</th>\n",
              "      <th>meanThr_UL</th>\n",
              "      <th>maxThr_DL</th>\n",
              "      <th>maxThr_UL</th>\n",
              "      <th>meanUE_DL</th>\n",
              "      <th>meanUE_UL</th>\n",
              "      <th>maxUE_DL</th>\n",
              "      <th>maxUE_UL</th>\n",
              "      <th>maxUE_UL+DL</th>\n",
              "      <th>Unusual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.226794</td>\n",
              "      <td>0.017973</td>\n",
              "      <td>0.018877</td>\n",
              "      <td>0.003290</td>\n",
              "      <td>0.111815</td>\n",
              "      <td>0.013346</td>\n",
              "      <td>0.382161</td>\n",
              "      <td>0.384183</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.424503</td>\n",
              "      <td>0.024398</td>\n",
              "      <td>0.027397</td>\n",
              "      <td>0.021507</td>\n",
              "      <td>0.073374</td>\n",
              "      <td>0.023916</td>\n",
              "      <td>0.464151</td>\n",
              "      <td>0.406672</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.009701</td>\n",
              "      <td>0.005135</td>\n",
              "      <td>0.000765</td>\n",
              "      <td>0.000803</td>\n",
              "      <td>0.001871</td>\n",
              "      <td>0.003399</td>\n",
              "      <td>0.341338</td>\n",
              "      <td>0.372939</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.086957</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.036838</td>\n",
              "      <td>0.014128</td>\n",
              "      <td>0.047957</td>\n",
              "      <td>0.001926</td>\n",
              "      <td>0.433654</td>\n",
              "      <td>0.017097</td>\n",
              "      <td>0.355060</td>\n",
              "      <td>0.372939</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.005213</td>\n",
              "      <td>0.000816</td>\n",
              "      <td>0.001043</td>\n",
              "      <td>0.002486</td>\n",
              "      <td>0.003482</td>\n",
              "      <td>0.346827</td>\n",
              "      <td>0.378936</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.130435</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36899</th>\n",
              "      <td>0.147644</td>\n",
              "      <td>0.010425</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.002969</td>\n",
              "      <td>0.056997</td>\n",
              "      <td>0.007772</td>\n",
              "      <td>0.377702</td>\n",
              "      <td>0.003748</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36900</th>\n",
              "      <td>0.177176</td>\n",
              "      <td>0.015651</td>\n",
              "      <td>0.009642</td>\n",
              "      <td>0.002408</td>\n",
              "      <td>0.139349</td>\n",
              "      <td>0.032806</td>\n",
              "      <td>0.384906</td>\n",
              "      <td>0.386432</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36901</th>\n",
              "      <td>0.085286</td>\n",
              "      <td>0.011561</td>\n",
              "      <td>0.017397</td>\n",
              "      <td>0.002408</td>\n",
              "      <td>0.085974</td>\n",
              "      <td>0.011191</td>\n",
              "      <td>0.365352</td>\n",
              "      <td>0.376687</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36902</th>\n",
              "      <td>0.259852</td>\n",
              "      <td>0.035198</td>\n",
              "      <td>0.028519</td>\n",
              "      <td>0.005216</td>\n",
              "      <td>0.201324</td>\n",
              "      <td>0.018527</td>\n",
              "      <td>0.419554</td>\n",
              "      <td>0.397676</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36903</th>\n",
              "      <td>0.433074</td>\n",
              "      <td>0.033895</td>\n",
              "      <td>0.041528</td>\n",
              "      <td>0.006099</td>\n",
              "      <td>0.577138</td>\n",
              "      <td>0.017657</td>\n",
              "      <td>0.454202</td>\n",
              "      <td>0.428036</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>36904 rows  12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1addc1e4-d249-42df-a51d-02400e1b95ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1addc1e4-d249-42df-a51d-02400e1b95ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1addc1e4-d249-42df-a51d-02400e1b95ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalization of test Dataset**"
      ],
      "metadata": {
        "id": "P47wtS5P5vQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np = min_max_scaler.fit_transform(data_test)\n",
        "\n",
        "df_test = pd.DataFrame(np, columns = data_test.columns)\n",
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "b8RUrZ_n5CLC",
        "outputId": "6d17efb5-407b-42ad-fd47-b9ffd40a6a4c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      PRBUsageUL  PRBUsageDL  meanThr_DL  meanThr_UL  maxThr_DL  maxThr_UL  \\\n",
              "0       0.080641    0.019314    0.038257    0.014042   0.191589   0.015769   \n",
              "1       0.043104    0.043142    0.037858    0.025075   0.247444   0.022263   \n",
              "2       0.010771    0.005226    0.000931    0.003343   0.001919   0.002059   \n",
              "3       0.021562    0.006533    0.015835    0.007021   0.177240   0.012925   \n",
              "4       0.082773    0.006442    0.005057    0.013708   0.033280   0.037523   \n",
              "...          ...         ...         ...         ...        ...        ...   \n",
              "9153    0.150873    0.013078    0.022954    0.015714   0.148610   0.019674   \n",
              "9154    0.002133    0.006442    0.003127    0.003678   0.040416   0.007237   \n",
              "9155    0.025871    0.006533    0.013906    0.008024   0.056820   0.008935   \n",
              "9156    0.116386    0.014385    0.031537    0.007690   0.038962   0.006367   \n",
              "9157    0.030179    0.005226    0.002728    0.003009   0.038607   0.003948   \n",
              "\n",
              "      meanUE_DL  meanUE_UL  maxUE_DL  maxUE_UL  maxUE_UL+DL  \n",
              "0      0.336177   0.004625  0.272727       0.2     0.238095  \n",
              "1      0.448464   0.004625  0.545455       0.3     0.428571  \n",
              "2      0.345051   0.004625  0.181818       0.1     0.142857  \n",
              "3      0.345051   0.467623  0.181818       0.1     0.142857  \n",
              "4      0.349829   0.004625  0.272727       0.2     0.238095  \n",
              "...         ...        ...       ...       ...          ...  \n",
              "9153   0.393174   0.476873  0.454545       0.3     0.380952  \n",
              "9154   0.356655   0.004625  0.272727       0.2     0.238095  \n",
              "9155   0.348464   0.467623  0.181818       0.1     0.142857  \n",
              "9156   0.365529   0.472248  0.363636       0.2     0.285714  \n",
              "9157   0.348464   0.467623  0.272727       0.2     0.238095  \n",
              "\n",
              "[9158 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cab2c0be-e926-4fed-b5f0-5f3a163d5b76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRBUsageUL</th>\n",
              "      <th>PRBUsageDL</th>\n",
              "      <th>meanThr_DL</th>\n",
              "      <th>meanThr_UL</th>\n",
              "      <th>maxThr_DL</th>\n",
              "      <th>maxThr_UL</th>\n",
              "      <th>meanUE_DL</th>\n",
              "      <th>meanUE_UL</th>\n",
              "      <th>maxUE_DL</th>\n",
              "      <th>maxUE_UL</th>\n",
              "      <th>maxUE_UL+DL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.080641</td>\n",
              "      <td>0.019314</td>\n",
              "      <td>0.038257</td>\n",
              "      <td>0.014042</td>\n",
              "      <td>0.191589</td>\n",
              "      <td>0.015769</td>\n",
              "      <td>0.336177</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.043104</td>\n",
              "      <td>0.043142</td>\n",
              "      <td>0.037858</td>\n",
              "      <td>0.025075</td>\n",
              "      <td>0.247444</td>\n",
              "      <td>0.022263</td>\n",
              "      <td>0.448464</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.010771</td>\n",
              "      <td>0.005226</td>\n",
              "      <td>0.000931</td>\n",
              "      <td>0.003343</td>\n",
              "      <td>0.001919</td>\n",
              "      <td>0.002059</td>\n",
              "      <td>0.345051</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.021562</td>\n",
              "      <td>0.006533</td>\n",
              "      <td>0.015835</td>\n",
              "      <td>0.007021</td>\n",
              "      <td>0.177240</td>\n",
              "      <td>0.012925</td>\n",
              "      <td>0.345051</td>\n",
              "      <td>0.467623</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.082773</td>\n",
              "      <td>0.006442</td>\n",
              "      <td>0.005057</td>\n",
              "      <td>0.013708</td>\n",
              "      <td>0.033280</td>\n",
              "      <td>0.037523</td>\n",
              "      <td>0.349829</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9153</th>\n",
              "      <td>0.150873</td>\n",
              "      <td>0.013078</td>\n",
              "      <td>0.022954</td>\n",
              "      <td>0.015714</td>\n",
              "      <td>0.148610</td>\n",
              "      <td>0.019674</td>\n",
              "      <td>0.393174</td>\n",
              "      <td>0.476873</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.380952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9154</th>\n",
              "      <td>0.002133</td>\n",
              "      <td>0.006442</td>\n",
              "      <td>0.003127</td>\n",
              "      <td>0.003678</td>\n",
              "      <td>0.040416</td>\n",
              "      <td>0.007237</td>\n",
              "      <td>0.356655</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.238095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9155</th>\n",
              "      <td>0.025871</td>\n",
              "      <td>0.006533</td>\n",
              "      <td>0.013906</td>\n",
              "      <td>0.008024</td>\n",
              "      <td>0.056820</td>\n",
              "      <td>0.008935</td>\n",
              "      <td>0.348464</td>\n",
              "      <td>0.467623</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9156</th>\n",
              "      <td>0.116386</td>\n",
              "      <td>0.014385</td>\n",
              "      <td>0.031537</td>\n",
              "      <td>0.007690</td>\n",
              "      <td>0.038962</td>\n",
              "      <td>0.006367</td>\n",
              "      <td>0.365529</td>\n",
              "      <td>0.472248</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9157</th>\n",
              "      <td>0.030179</td>\n",
              "      <td>0.005226</td>\n",
              "      <td>0.002728</td>\n",
              "      <td>0.003009</td>\n",
              "      <td>0.038607</td>\n",
              "      <td>0.003948</td>\n",
              "      <td>0.348464</td>\n",
              "      <td>0.467623</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.238095</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9158 rows  11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cab2c0be-e926-4fed-b5f0-5f3a163d5b76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cab2c0be-e926-4fed-b5f0-5f3a163d5b76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cab2c0be-e926-4fed-b5f0-5f3a163d5b76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing values**"
      ],
      "metadata": {
        "id": "J91JCpPTWZ89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = [0,1,2,3,4,5,6,7,8,9]\n",
        "print(b[::3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK7IUrtkH9DF",
        "outputId": "df79fe06-22d2-4339-8976-bc69addbde9d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 3, 6, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XUB5CErPIITi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = data_train.isnull().sum()\n",
        "b = data_test.isnull().sum()\n",
        "missing_value_feature_all_data = []\n",
        "\n",
        "def find_missing(df):\n",
        "  for i in df.index:\n",
        "    \n",
        "    if df[i] != 0:\n",
        "      missing_value_feature_all_data.append(i)\n",
        "\n",
        "  print(missing_value_feature_all_data)\n",
        "\n",
        "find_missing(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ree86_7mWVJi",
        "outputId": "17cfccee-f72e-451b-b42e-d0cdb9481137"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['maxUE_DL', 'maxUE_UL', 'maxUE_UL+DL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_missing(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlvLf86qnjIE",
        "outputId": "8f4d613e-c943-4c05-be48-f3a91e321e9b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['maxUE_DL', 'maxUE_UL', 'maxUE_UL+DL', 'maxUE_DL', 'maxUE_UL', 'maxUE_UL+DL']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.isnull().sum() * 100 / len(data_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32HsL94SoSEi",
        "outputId": "6a708956-3dfc-48c1-ac9e-9caf328cdbd7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PRBUsageUL     0.000000\n",
              "PRBUsageDL     0.000000\n",
              "meanThr_DL     0.000000\n",
              "meanThr_UL     0.000000\n",
              "maxThr_DL      0.000000\n",
              "maxThr_UL      0.000000\n",
              "meanUE_DL      0.000000\n",
              "meanUE_UL      0.000000\n",
              "maxUE_DL       0.241166\n",
              "maxUE_UL       0.241166\n",
              "maxUE_UL+DL    0.013549\n",
              "Unusual        0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test.isnull().sum() * 100 / len(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAlZ79KBz10g",
        "outputId": "d76610cc-af19-413a-e4b3-843749c0e729"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PRBUsageUL     0.000000\n",
              "PRBUsageDL     0.000000\n",
              "meanThr_DL     0.000000\n",
              "meanThr_UL     0.000000\n",
              "maxThr_DL      0.000000\n",
              "maxThr_UL      0.000000\n",
              "meanUE_DL      0.000000\n",
              "meanUE_UL      0.000000\n",
              "maxUE_DL       0.021839\n",
              "maxUE_UL       0.021839\n",
              "maxUE_UL+DL    0.021839\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling missing values**"
      ],
      "metadata": {
        "id": "fvSrMAh3oBLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data_train.fillna(method='ffill').fillna(method='bfill')\n",
        "data_test = data_test.fillna(method='ffill').fillna(method='bfill')"
      ],
      "metadata": {
        "id": "N5so1PDcoDL6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data_train.drop(columns = ['Unusual'], axis = 1)\n",
        "y = data_train['Unusual']\n",
        "\n",
        "x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.2,random_state = 1)"
      ],
      "metadata": {
        "id": "3uqxdcN9CANB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0_DFVzHXDo7Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_train.drop(columns = ['Unusual'], axis = 1)\n",
        "y = data_train['Unusual']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "nWw_todHDmc2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y5giECdPDyHJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
        "    if train:\n",
        "        pred = clf.predict(X_train)\n",
        "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
        "        print(\"Train Result:\\n================================================\")\n",
        "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
        "        \n",
        "    elif train==False:\n",
        "        pred = clf.predict(X_test)\n",
        "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
        "        print(\"Test Result:\\n================================================\")        \n",
        "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
      ],
      "metadata": {
        "id": "XqlERNCBCS2d"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u5QENARZDy_e"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression(solver='liblinear')\n",
        "lr_clf.fit(X_train, y_train)\n",
        "\n",
        "print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\n",
        "print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zUYQll4C4aC",
        "outputId": "9da938f8-17d5-4dc0-c7b6-f32f1dbbf3c9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 72.07%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                      0            1  accuracy     macro avg  weighted avg\n",
            "precision      0.723771     0.201299  0.720657      0.462535      0.579683\n",
            "recall         0.993425     0.004351  0.720657      0.498888      0.720657\n",
            "f1-score       0.837426     0.008519  0.720657      0.422973      0.608828\n",
            "support    18708.000000  7124.000000  0.720657  25832.000000  25832.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[18585   123]\n",
            " [ 7093    31]]\n",
            "\n",
            "Test Result:\n",
            "================================================\n",
            "Accuracy Score: 71.97%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                     0            1  accuracy     macro avg  weighted avg\n",
            "precision     0.723263     0.210526  0.719743      0.466895      0.581603\n",
            "recall        0.992512     0.005230  0.719743      0.498871      0.719743\n",
            "f1-score      0.836762     0.010207  0.719743      0.423484      0.608399\n",
            "support    8013.000000  3059.000000  0.719743  11072.000000  11072.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[7953   60]\n",
            " [3043   16]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lil69RJUDBfa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking imbalance in target variable**"
      ],
      "metadata": {
        "id": "Dx5oP6GnX2P3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data_train['Unusual'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "wQm8AtbWXOhG",
        "outputId": "a425aa30-a286-4764-acfe-a224fb782458"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5bae8a65e0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nugwu1PA0ITg"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def over_sample_train_test(x,y):\n",
        "    ros=RandomOverSampler(random_state=10)\n",
        "    ros.fit(x,y)\n",
        "    x_res,y_res=ros.fit_resample(x,y)\n",
        "    x_train,x_val,y_train,y_val=train_test_split(x_res,y_res,test_size=0.3,random_state = 1)\n",
        "#     x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.2,random_state = 1) # if without oversampling\n",
        "    return x_train,x_val,y_train,y_val\n",
        "\n",
        "x = data_train.drop(columns = ['Unusual'], axis = 1)\n",
        "y = data_train.Unusual\n",
        "x_train,x_val,y_train,y_val = over_sample_train_test(x, y)"
      ],
      "metadata": {
        "id": "P4sM8xXjYB_3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize = (10,4))\n",
        "sns.histplot(y_train, ax = ax1)\n",
        "sns.histplot(y_val, ax = ax2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "SSHmsOFTmIaC",
        "outputId": "ecfe47ed-356b-47a8-91e2-b94b625dfcb3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5baec1a1c0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "EpxQ6fhTmOMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = LogisticRegression(solver='liblinear', penalty = 'l1', C = 0.05, random_state = 42, max_iter = 1000)\n",
        "regulation_parameter = 0.005\n",
        "lr = LogisticRegression(solver='liblinear', C = regulation_parameter, random_state = 42, max_iter = 1000)\n",
        "\n",
        "def apply_model(model,x_train,x_val,y_train,y_val):\n",
        "    print('Logistic Regression')\n",
        "    model.fit(x_train,y_train)\n",
        "    y_pred = model.predict(x_val)\n",
        "    print('')\n",
        "    print('Train Score:  ',model.score(x_train,y_train))\n",
        "    print('Validation Score:   ',model.score(x_val,y_val))\n",
        "    print('')\n",
        "    plot_confusion_matrix(model, x_val, y_val)\n",
        "    print(classification_report(y_val,y_pred))\n",
        "\n",
        "apply_model(lr, x_train,x_val,y_train,y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "Wx_U3NMlmQLo",
        "outputId": "604ce761-2f65-4983-df16-707bceb0725b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "\n",
            "Train Score:   0.5790852468657275\n",
            "Validation Score:    0.5783696126738601\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.49      0.54      8065\n",
            "           1       0.56      0.67      0.61      7968\n",
            "\n",
            "    accuracy                           0.58     16033\n",
            "   macro avg       0.58      0.58      0.58     16033\n",
            "weighted avg       0.58      0.58      0.57     16033\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = LogisticRegression(solver='liblinear', penalty = 'l1', C = 0.05, random_state = 42, max_iter = 1000)\n",
        "\n",
        "\n",
        "def apply_model(model,x_train,x_val,y_train,y_val):\n",
        "    print('Logistic Regression')\n",
        "    model.fit(x_train,y_train)\n",
        "    y_pred = model.predict(x_val)\n",
        "    print('')\n",
        "    print('Train Score:  ',model.score(x_train,y_train))\n",
        "    print('Validation Score:   ',model.score(x_val,y_val))\n",
        "    print('')\n",
        "    plot_confusion_matrix(model, x_val, y_val)\n",
        "    print(classification_report(y_val,y_pred))\n",
        "\n",
        "apply_model(lasso, x_train,x_val,y_train,y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "A9l3I_Qf1Lna",
        "outputId": "391a15d1-afec-4f4e-a111-319bc33f8e78"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression\n",
            "\n",
            "Train Score:   0.6248763666497367\n",
            "Validation Score:    0.6211563649971933\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.46      0.55      8065\n",
            "           1       0.59      0.78      0.67      7968\n",
            "\n",
            "    accuracy                           0.62     16033\n",
            "   macro avg       0.64      0.62      0.61     16033\n",
            "weighted avg       0.64      0.62      0.61     16033\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dltem02-zq0k"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Network**"
      ],
      "metadata": {
        "id": "rHblU6ZJ2NAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_train.drop(columns = ['Unusual'], axis = 1)\n",
        "y = data_train['Unusual']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "MY6n6ntL2dha"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = X_train.shape[1]  # second index = 11\n",
        "batch_size = len(X_train)  # = N train. Whole training dataset used per epoch\n",
        "\n",
        "# Print shapes / dataset lengths\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n",
        "# Scale inputs to improve loss convergence\n",
        "\n",
        "X_train = preprocessing.scale(X_train, axis=0, with_mean=True, with_std=True, copy= False)\n",
        "X_test = preprocessing.scale(X_test, axis=0,with_mean=True,with_std = True, copy = False)"
      ],
      "metadata": {
        "id": "qTL2UoGZ6mV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407bbdb9-bc9d-48cc-ad94-bf03ec69c879"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29523, 11) (29523,)\n",
            "(7381, 11) (7381,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential # initialize neural network library\n",
        "from keras.layers import Dense # build our layers library\n",
        "\n",
        "def build_classifier():\n",
        "    classifier = Sequential() # initialize neural network\n",
        "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
        "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 3)\n",
        "\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()\n",
        "\n",
        "print(\"Accuracy mean: \"+ str(mean))\n",
        "print(\"Accuracy variance: \"+ str(variance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvuSlG9Y-B4T",
        "outputId": "fd668cd4-1fc5-4617-9037-9e95ac0a85e2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-e64f2c8e39cf>:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "616/616 [==============================] - 2s 2ms/step - loss: 0.5952 - accuracy: 0.7255\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7256\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7256\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7256\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5536 - accuracy: 0.7256\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5508 - accuracy: 0.7256\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5485 - accuracy: 0.7256\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7256\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5456 - accuracy: 0.7256\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7256\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5438 - accuracy: 0.7256\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7257\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7260\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7251\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7258\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7260\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7260\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7266\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7273\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7272\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7281\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7280\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7281\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7277\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7292\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7283\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7289\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7290\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7302\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7314\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7314\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7323\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7314\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7327\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7325\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7315\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7333\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7330\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7331\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7330\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7336\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7329\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7326\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7335\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7341\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7323\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7330\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7335\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7346\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7334\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7323\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7336\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7344\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7331\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7335\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7341\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7338\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7345\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7340\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7343\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7346\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7333\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7348\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7350\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7344\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7348\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7348\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7344\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7352\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7354\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7355\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7356\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7350\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7349\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7333\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7351\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7340\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7341\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7354\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7341\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7362\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7353\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7344\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7343\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7349\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7333\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7343\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7335\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7350\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7347\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7350\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7329\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7364\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7346\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7346\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7356\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7345\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7350\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7343\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7344\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7316\n",
            "Epoch 1/100\n",
            "616/616 [==============================] - 2s 2ms/step - loss: 0.5970 - accuracy: 0.7225\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5690 - accuracy: 0.7227\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7227\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5618 - accuracy: 0.7227\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7227\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5555 - accuracy: 0.7227\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.7227\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5517 - accuracy: 0.7227\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5500 - accuracy: 0.7227\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5490 - accuracy: 0.7227\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5485 - accuracy: 0.7227\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5475 - accuracy: 0.7227\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5471 - accuracy: 0.7227\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5463 - accuracy: 0.7225\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7188\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7179\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7175\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7192\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5446 - accuracy: 0.7191\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5443 - accuracy: 0.7206\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7208\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.7210\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7207\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7251\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7237\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7256\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7249\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7251\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5412 - accuracy: 0.7262\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7254\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7274\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7271\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7278\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7291\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7293\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7291\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7295\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7290\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7292\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7289\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7285\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7287\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7294\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7290\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7298\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7289\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7298\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7295\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7297\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7286\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7289\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7292\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7293\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7290\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7303\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7291\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7295\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7293\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7295\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5372 - accuracy: 0.7294\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5368 - accuracy: 0.7302\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 2s 2ms/step - loss: 0.5369 - accuracy: 0.7291\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7292\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7289\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7282\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7292\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7287\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7298\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7285\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7290\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7296\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7286\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7293\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7307\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5357 - accuracy: 0.7285\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7294\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7281\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7287\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7284\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7286\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7287\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7294\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7291\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7287\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7290\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7291\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7283\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7299\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7277\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7289\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7288\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7285\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7294\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7292\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7300\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7281\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7294\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7293\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7288\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7305\n",
            "308/308 [==============================] - 1s 1ms/step - loss: 0.5303 - accuracy: 0.7439\n",
            "Epoch 1/100\n",
            "616/616 [==============================] - 2s 2ms/step - loss: 0.6009 - accuracy: 0.7243\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7248\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7248\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5616 - accuracy: 0.7248\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5582 - accuracy: 0.7248\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5551 - accuracy: 0.7248\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5521 - accuracy: 0.7248\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5493 - accuracy: 0.7248\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5474 - accuracy: 0.7248\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7248\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5449 - accuracy: 0.7248\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7248\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5434 - accuracy: 0.7245\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7203\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7206\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7218\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7215\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7231\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7221\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7224\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7230\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7229\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7232\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5396 - accuracy: 0.7243\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7243\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7256\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7261\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7256\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7276\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5376 - accuracy: 0.7267\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7270\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7279\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7276\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7289\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7313\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7326\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7327\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7333\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7339\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7346\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7351\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7360\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7352\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7348\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7359\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7359\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7373\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7357\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7353\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7367\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7350\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7362\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7356\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7357\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7361\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7356\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7348\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7361\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7372\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7368\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7356\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7376\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7355\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7388\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7411\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5255 - accuracy: 0.7446\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.7469\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5196 - accuracy: 0.7494\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7522\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5131 - accuracy: 0.7551\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7577\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5071 - accuracy: 0.7577\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.7601\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.7619\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.7615\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4994 - accuracy: 0.7646\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4988 - accuracy: 0.7627\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4968 - accuracy: 0.7644\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4960 - accuracy: 0.7647\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4954 - accuracy: 0.7661\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4949 - accuracy: 0.7657\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4938 - accuracy: 0.7676\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4923 - accuracy: 0.7672\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4917 - accuracy: 0.7676\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.7697\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4901 - accuracy: 0.7689\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4891 - accuracy: 0.7717\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4881 - accuracy: 0.7707\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.7710\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4869 - accuracy: 0.7718\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7726\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.7726\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7717\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4846 - accuracy: 0.7745\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4852 - accuracy: 0.7734\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7736\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7749\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4829 - accuracy: 0.7745\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.7749\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4826 - accuracy: 0.7730\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.4916 - accuracy: 0.7665\n",
            "Accuracy mean: 0.7473495205243429\n",
            "Accuracy variance: 0.014433316369962815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Changing the neurons in 1st and 2nd layer from (8,4,1) to (6,6,1)**"
      ],
      "metadata": {
        "id": "c-WFZEmmJNIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential # initialize neural network library\n",
        "from keras.layers import Dense # build our layers library\n",
        "\n",
        "def build_classifier():\n",
        "    classifier = Sequential() # initialize neural network\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 3)\n",
        "\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()\n",
        "\n",
        "print(\"Accuracy mean: \"+ str(mean))\n",
        "print(\"Accuracy variance: \"+ str(variance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYPbkWzfFDkN",
        "outputId": "317eadc0-2a5a-47c1-9a16-83951f687030"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-53aaa1828ffa>:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "616/616 [==============================] - 2s 2ms/step - loss: 0.5954 - accuracy: 0.7251\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5660 - accuracy: 0.7256\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5630 - accuracy: 0.7256\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5608 - accuracy: 0.7256\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.7256\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5563 - accuracy: 0.7256\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5535 - accuracy: 0.7256\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5515 - accuracy: 0.7256\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7256\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5489 - accuracy: 0.7256\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5475 - accuracy: 0.7256\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5465 - accuracy: 0.7256\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5459 - accuracy: 0.7256\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7253\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7245\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7249\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7248\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7249\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7256\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5416 - accuracy: 0.7258\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7260\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5402 - accuracy: 0.7262\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7273\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7273\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5391 - accuracy: 0.7270\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7272\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7269\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7270\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7275\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7274\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7277\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5377 - accuracy: 0.7276\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7283\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7285\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7285\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7285\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7294\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7287\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7297\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5361 - accuracy: 0.7293\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7307\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7292\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5350 - accuracy: 0.7304\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5351 - accuracy: 0.7311\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7310\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7315\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7312\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7322\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5343 - accuracy: 0.7318\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7316\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7316\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7323\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7317\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5334 - accuracy: 0.7324\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7320\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7325\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7329\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7322\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7339\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7329\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7339\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7335\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7330\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7325\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7336\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7339\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7351\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7344\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7349\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7347\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7349\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7331\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7337\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7346\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7348\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7350\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7352\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7343\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7338\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7357\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7342\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7351\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7357\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7349\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7361\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7359\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7354\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7346\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5311 - accuracy: 0.7348\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7354\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7353\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7361\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5308 - accuracy: 0.7353\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7353\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5309 - accuracy: 0.7353\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7364\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7376\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5302 - accuracy: 0.7367\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7364\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5306 - accuracy: 0.7363\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7332\n",
            "Epoch 1/100\n",
            "616/616 [==============================] - 2s 2ms/step - loss: 0.5960 - accuracy: 0.7225\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5683 - accuracy: 0.7227\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5627 - accuracy: 0.7227\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7227\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5551 - accuracy: 0.7227\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5522 - accuracy: 0.7227\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5504 - accuracy: 0.7227\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5491 - accuracy: 0.7227\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5484 - accuracy: 0.7227\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5475 - accuracy: 0.7223\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7203\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7180\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5458 - accuracy: 0.7176\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7183\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7184\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7201\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7194\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7214\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7216\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7214\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7215\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5425 - accuracy: 0.7242\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7237\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5415 - accuracy: 0.7254\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5414 - accuracy: 0.7251\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5410 - accuracy: 0.7259\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7262\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7256\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7260\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7267\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7274\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7270\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5405 - accuracy: 0.7267\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5404 - accuracy: 0.7275\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7284\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7282\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7284\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7279\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7277\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7291\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7289\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5398 - accuracy: 0.7282\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7290\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5397 - accuracy: 0.7276\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7294\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7275\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7280\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7278\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7289\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7278\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7292\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7287\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7304\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5388 - accuracy: 0.7286\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7301\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7294\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7292\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5386 - accuracy: 0.7287\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7291\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7300\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7287\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7300\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7284\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5381 - accuracy: 0.7315\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7293\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7276\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7286\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5379 - accuracy: 0.7298\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7303\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5378 - accuracy: 0.7298\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5374 - accuracy: 0.7287\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7304\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7303\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7307\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5371 - accuracy: 0.7302\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5368 - accuracy: 0.7308\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5370 - accuracy: 0.7301\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5367 - accuracy: 0.7296\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5369 - accuracy: 0.7317\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7289\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7315\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7299\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7298\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7300\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5360 - accuracy: 0.7300\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5362 - accuracy: 0.7309\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5358 - accuracy: 0.7303\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5356 - accuracy: 0.7302\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5359 - accuracy: 0.7295\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7299\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7305\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7322\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7297\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7316\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5354 - accuracy: 0.7305\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7309\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7302\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7320\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7306\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7309\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.5277 - accuracy: 0.7399\n",
            "Epoch 1/100\n",
            "616/616 [==============================] - 2s 2ms/step - loss: 0.5952 - accuracy: 0.7248\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7248\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.7248\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5524 - accuracy: 0.7248\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5486 - accuracy: 0.7248\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7248\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5447 - accuracy: 0.7248\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5439 - accuracy: 0.7247\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7241\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5422 - accuracy: 0.7242\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7258\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5413 - accuracy: 0.7258\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5408 - accuracy: 0.7270\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5407 - accuracy: 0.7273\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.7292\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5395 - accuracy: 0.7285\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5394 - accuracy: 0.7296\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7305\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5383 - accuracy: 0.7304\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7317\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5375 - accuracy: 0.7304\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5366 - accuracy: 0.7302\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7322\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5355 - accuracy: 0.7340\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5352 - accuracy: 0.7335\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.7343\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5346 - accuracy: 0.7343\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7344\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5348 - accuracy: 0.7337\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7358\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7352\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5338 - accuracy: 0.7366\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7365\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5341 - accuracy: 0.7357\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5335 - accuracy: 0.7352\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5339 - accuracy: 0.7367\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.7359\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5333 - accuracy: 0.7369\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7374\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7367\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7368\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7378\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7386\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7368\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7387\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7379\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5330 - accuracy: 0.7375\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5331 - accuracy: 0.7370\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.7378\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7377\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7372\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7374\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5327 - accuracy: 0.7371\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7380\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7363\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7378\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7394\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7368\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7380\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7364\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5322 - accuracy: 0.7382\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7374\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7379\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7378\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7386\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7376\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7388\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7382\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7373\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7385\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7396\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5319 - accuracy: 0.7393\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7388\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7382\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7364\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7378\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7386\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7366\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7374\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7378\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5321 - accuracy: 0.7373\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7383\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7391\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7379\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7392\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7377\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7373\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7391\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5317 - accuracy: 0.7395\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7383\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7390\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5320 - accuracy: 0.7392\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7392\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7373\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5313 - accuracy: 0.7383\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7381\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5314 - accuracy: 0.7377\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7387\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.7395\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5310 - accuracy: 0.7387\n",
            "308/308 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7312\n",
            "Accuracy mean: 0.7347491780916849\n",
            "Accuracy variance: 0.0037014889706351367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Increasing one more layer in the neural network to change shape from (6,6,1) to (6,4,2,1)**"
      ],
      "metadata": {
        "id": "qPx4HAcoJc_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the ANN\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential # initialize neural network library\n",
        "from keras.layers import Dense # build our layers library\n",
        "\n",
        "def build_classifier():\n",
        "    classifier = Sequential() # initialize neural network\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = x_train.shape[1]))\n",
        "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 3)\n",
        "\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()\n",
        "\n",
        "print(\"Accuracy mean: \"+ str(mean))\n",
        "print(\"Accuracy variance: \"+ str(variance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1hLDxvWJnxV",
        "outputId": "e2c540cb-b5ab-4274-bb2a-99a4db3ef476"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-319277fafabf>:16: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "616/616 [==============================] - 2s 2ms/step - loss: 0.6462 - accuracy: 0.7253\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.6007 - accuracy: 0.7256\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.7256\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5878 - accuracy: 0.7256\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5877 - accuracy: 0.7256\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5877 - accuracy: 0.7256\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5876 - accuracy: 0.7256\n",
            "308/308 [==============================] - 1s 1ms/step - loss: 0.5912 - accuracy: 0.7220\n",
            "Epoch 1/100\n",
            "616/616 [==============================] - 2s 2ms/step - loss: 0.6077 - accuracy: 0.7226\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5727 - accuracy: 0.7227\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5697 - accuracy: 0.7227\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5674 - accuracy: 0.7227\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7227\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7227\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5594 - accuracy: 0.7227\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5570 - accuracy: 0.7227\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5547 - accuracy: 0.7227\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5514 - accuracy: 0.7227\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5479 - accuracy: 0.7227\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5440 - accuracy: 0.7227\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.7227\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5365 - accuracy: 0.7227\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7269\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5312 - accuracy: 0.7364\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5295 - accuracy: 0.7395\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5279 - accuracy: 0.7413\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7441\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5246 - accuracy: 0.7445\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5226 - accuracy: 0.7474\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7486\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7498\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.7510\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.7530\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5153 - accuracy: 0.7540\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7539\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5132 - accuracy: 0.7551\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.7557\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5116 - accuracy: 0.7560\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.7552\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5103 - accuracy: 0.7569\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5101 - accuracy: 0.7558\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5092 - accuracy: 0.7586\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5086 - accuracy: 0.7575\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7594\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5080 - accuracy: 0.7596\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5072 - accuracy: 0.7586\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5071 - accuracy: 0.7590\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5076 - accuracy: 0.7600\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7602\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5064 - accuracy: 0.7603\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7619\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5063 - accuracy: 0.7603\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7619\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5051 - accuracy: 0.7634\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7631\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5041 - accuracy: 0.7628\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.7636\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7647\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.7631\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.7643\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.7656\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.7642\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5019 - accuracy: 0.7658\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5018 - accuracy: 0.7644\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5013 - accuracy: 0.7659\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5005 - accuracy: 0.7670\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.7650\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.7685\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5005 - accuracy: 0.7662\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5004 - accuracy: 0.7665\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7660\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5004 - accuracy: 0.7670\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4996 - accuracy: 0.7670\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7663\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4991 - accuracy: 0.7676\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4981 - accuracy: 0.7685\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4993 - accuracy: 0.7680\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4982 - accuracy: 0.7672\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4981 - accuracy: 0.7681\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4983 - accuracy: 0.7684\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4975 - accuracy: 0.7676\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4980 - accuracy: 0.7684\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4974 - accuracy: 0.7685\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4993 - accuracy: 0.7669\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4983 - accuracy: 0.7678\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4963 - accuracy: 0.7699\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4966 - accuracy: 0.7693\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4966 - accuracy: 0.7688\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4975 - accuracy: 0.7673\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4966 - accuracy: 0.7690\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4973 - accuracy: 0.7690\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4958 - accuracy: 0.7697\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4963 - accuracy: 0.7698\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4966 - accuracy: 0.7697\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4959 - accuracy: 0.7706\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4965 - accuracy: 0.7698\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4970 - accuracy: 0.7692\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4963 - accuracy: 0.7695\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4957 - accuracy: 0.7698\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4959 - accuracy: 0.7698\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4962 - accuracy: 0.7704\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4956 - accuracy: 0.7700\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.7701\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4948 - accuracy: 0.7706\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4941 - accuracy: 0.7716\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4948 - accuracy: 0.7704\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4942 - accuracy: 0.7707\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.4969 - accuracy: 0.7685\n",
            "308/308 [==============================] - 1s 1ms/step - loss: 0.4925 - accuracy: 0.7731\n",
            "Epoch 1/100\n",
            "616/616 [==============================] - 2s 2ms/step - loss: 0.6460 - accuracy: 0.7246\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.6009 - accuracy: 0.7248\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5903 - accuracy: 0.7248\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5886 - accuracy: 0.7248\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.7248\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 2s 3ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.5884 - accuracy: 0.7248\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.7235\n",
            "Accuracy mean: 0.7395251194636027\n",
            "Accuracy variance: 0.02374363062572446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "11NTNDRuO9oC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iHNP1njoKhWJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_1e8QK6JLCE"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVEBIlo-BU1w"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TeQOZ8pg8sxA"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}